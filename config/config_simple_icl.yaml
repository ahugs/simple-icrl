defaults:
  - policy: irl_sac
  - reward: linear_mlp
  - collector: mod_fsrl
  - trainer: mod_safe_off_policy
  - data: icrl
  - logger: fsrl_wandb
  - env: inverted_pendulum
  - override hydra/launcher: submitit_local

train_env_num: 1
test_env_num: 5
train_buffer_size: 1000000
test_buffer_size: 10000
warmstart_episodes: 1
seed: 0
logger:
  name: ${task}-${seed}
  project: simple-icl
log_path: wandb/${now:%Y-%m-%d}_${now:%H-%M-%S}
device: cuda
reward:
  net:
    clip_range: [-20, 0]
reset_policy: False
normalize_reward: False
normalize_obs: False
policy:
  additive_reward: True