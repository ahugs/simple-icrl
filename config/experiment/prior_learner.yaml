# @package _global_
policy:
  lagrangian: 1
reset_policy: True
reward:
  lr_scheduler: null
  regularization_coeff: 0.9
  regularization_type: "prior_learner"
  optim:
    lr: 0.001
  net:
    preprocess_net:
      norm_layer:
        _target_: hydra.utils.get_class
        path: torch.nn.BatchNorm1d